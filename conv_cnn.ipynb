{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def get_data_with_n_labels_for_each_class(x_train_full, y_train_full, nr_of_labels, num_classes):\n",
    "    x_train_full, y_train_full = shuffle(x_train_full, y_train_full)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    min_queries = nr_of_labels * num_classes\n",
    "    x_train.extend(x_train_full[0:min_queries])\n",
    "    y_train.extend(y_train_full[0:min_queries])\n",
    "\n",
    "    for index in range(min_queries, y_train_full.size):\n",
    "        x_train.append(x_train_full[index])\n",
    "        y_train.append(y_train_full[index])\n",
    "        _, classes_counter = np.unique(np.array(y_train), return_counts=True)\n",
    "        if np.amin(classes_counter) == nr_of_labels:\n",
    "            print(\"Number of labels retrieved for training: \")\n",
    "            print(np.sum(classes_counter))\n",
    "            break\n",
    "\n",
    "    # TODO select random 500 from each class\n",
    "    return np.array(x_train), np.array(y_train), x_train_full[len(y_train):], y_train_full[len(y_train):]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1s8_M44GnVe8",
    "outputId": "ae8aa8db-ce63-446b-f2a7-b2c19137c63f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import keras.layers\n",
    "from keras.constraints import maxnorm\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self, num_classes=10, activation='relu', padding='same', dropout=0.2, shape=(28, 28, 1),\n",
    "                 pool_size=(2, 2), kernel_size=(3, 3)):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.inputs = keras.Input(shape=shape)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "        self.padding = padding\n",
    "        self.dropout = dropout\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def make_stem(self, filters=[32, 32, 64], shape=(32, 32, 3)):\n",
    "        filter1, filter2, filter3 = filters\n",
    "        stem = keras.layers.Conv2D(filter1, self.kernel_size, input_shape=shape, activation=self.activation,\n",
    "                                   padding=self.padding)(self.inputs)\n",
    "        stem = keras.layers.Conv2D(filter2, self.kernel_size, input_shape=shape, activation=self.activation,\n",
    "                                   padding=self.padding)(stem)\n",
    "        stem = keras.layers.Conv2D(filter3, self.kernel_size, input_shape=shape, activation=self.activation,\n",
    "                                   padding=self.padding)(stem)\n",
    "        stem = keras.layers.MaxPooling2D(self.kernel_size, strides=(2, 2), padding=self.padding)(stem)\n",
    "        return stem\n",
    "\n",
    "    def make_skip_connection(self, input, filter=64):\n",
    "        skip = keras.layers.Conv2D(filter, self.kernel_size, activation=self.activation, padding=self.padding)(input)\n",
    "        layer = keras.layers.Dropout(self.dropout)(skip)\n",
    "        layer = keras.layers.Conv2D(filter, self.kernel_size, padding=self.padding)(layer)\n",
    "        merge = keras.layers.add([layer, skip])\n",
    "        activation = keras.layers.Activation('relu')(merge)\n",
    "        return activation\n",
    "\n",
    "    def make_main_block(self, input, filter):\n",
    "        block = keras.layers.Conv2D(filter, self.kernel_size, activation=self.activation, padding=self.padding)(input)\n",
    "        block = keras.layers.Dropout(self.dropout)(block)\n",
    "        block = keras.layers.Conv2D(filter, self.kernel_size, activation=self.activation, padding=self.padding)(block)\n",
    "        block = keras.layers.MaxPooling2D(pool_size=self.pool_size)(block)\n",
    "        return block\n",
    "\n",
    "    def make_dense_dropout(self, input, filter, kernel_constraint=maxnorm(3)):\n",
    "        dense = keras.layers.Dense(filter, activation=self.activation, kernel_constraint=kernel_constraint)(input)\n",
    "        dropout = keras.layers.Dropout(self.dropout)(dense)\n",
    "        return dropout\n",
    "\n",
    "    def make_model(self):\n",
    "        output = self.make_stem()\n",
    "\n",
    "        output = self.make_skip_connection(output)\n",
    "\n",
    "        output = keras.layers.MaxPooling2D(pool_size=self.pool_size)(output)\n",
    "\n",
    "        output = self.make_main_block(output, 128)\n",
    "        output = self.make_main_block(output, 256)\n",
    "\n",
    "        output = keras.layers.Flatten()(output)\n",
    "        output = keras.layers.Dropout(self.dropout)(output)\n",
    "\n",
    "        output = self.make_dense_dropout(output, 1024)\n",
    "        output = self.make_dense_dropout(output, 512)\n",
    "\n",
    "        output = keras.layers.Dense(self.num_classes, activation='softmax')(output)\n",
    "\n",
    "        return keras.Model(inputs=self.inputs, outputs=output)\n",
    "\n",
    "    def compile_model(self, model):\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def build_model(self):\n",
    "        model = self.make_model()\n",
    "        print(model.summary())\n",
    "        self.compile_model(model)\n",
    "        return model"
   ],
   "metadata": {
    "id": "UZX1-tA0nVe-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "class MistFashionEngine:\n",
    "    def __init__(self, model):\n",
    "        super(MistFashionEngine, self).__init__()\n",
    "        self.model = model.build_model()\n",
    "        self.accuracy = 0\n",
    "        self.best_model = None\n",
    "\n",
    "    def classify_high_confidence(self, x_train_remaining, y_train_remaining, x_train, y_train):\n",
    "        input = x_train_remaining.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "        predictions = self.model.predict(input)\n",
    "        certainty = predictions.copy()\n",
    "        certainty = np.max(certainty, axis=1)\n",
    "        certainty = np.expand_dims(certainty, axis=1)\n",
    "\n",
    "        label = predictions.copy()\n",
    "        label = np.argmax(label, axis=1)\n",
    "\n",
    "        categ_label = to_categorical(label, num_classes=10)\n",
    "\n",
    "        certainty_threshold = 0.95\n",
    "        indices_over_threshold = np.where(np.any(certainty > certainty_threshold, axis=1))\n",
    "\n",
    "        # add data predicted with high confidence to the train data\n",
    "        x_train = np.append(x_train, input[indices_over_threshold], axis=0)\n",
    "        y_train = np.append(y_train, categ_label[indices_over_threshold], axis=0)\n",
    "\n",
    "        # delete data already labeled\n",
    "        x_train_remaining = np.delete(x_train_remaining, [indices_over_threshold], axis=0)\n",
    "        y_train_remaining = np.delete(y_train_remaining, [indices_over_threshold], axis=0)\n",
    "\n",
    "        print(\"Remaining unlabeled: \" + str(y_train_remaining.size))\n",
    "        return x_train, y_train, x_train_remaining, y_train_remaining\n",
    "\n",
    "    def evaluate_model(self, x_test, y_test):\n",
    "        loss, accuracy = self.model.evaluate(x_test, y_test)\n",
    "        print('loss = {}, accuracy = {}'.format(loss, accuracy))\n",
    "        if self.accuracy < accuracy:\n",
    "            self.accuracy = accuracy\n",
    "            self.best_model = self.model\n",
    "        return accuracy\n",
    "\n",
    "    def train_model(self, epochs, batch_size, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "    def save_best_model(self):\n",
    "        self.best_model.save(\"best.h5\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def main():\n",
    "    x_train_full, y_train_full = load_mnist('data', kind='train')\n",
    "    x_test, y_test = load_mnist('data', kind='t10k')\n",
    "    num_classes = 10\n",
    "\n",
    "    x_train, y_train, x_train_remaining, y_train_remaining = \\\n",
    "        get_data_with_n_labels_for_each_class(x_train_full,\n",
    "                                                   y_train_full,\n",
    "                                                   nr_of_labels=1000,\n",
    "                                                   num_classes=num_classes)\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    model = Model()\n",
    "    engine = MistFashionEngine(model)\n",
    "\n",
    "    best_model = None\n",
    "    engine.train_model(epochs=5, batch_size=64, x_train=x_train, y_train=y_train)\n",
    "\n",
    "    while y_train_remaining.size > 0:\n",
    "        curr_accuracy = engine.evaluate_model(x_test, y_test)\n",
    "        if curr_accuracy > 0.9:\n",
    "            engine.save_best_model()\n",
    "            break\n",
    "        x_train, y_train, x_train_remaining, y_train_remaining = engine.classify_high_confidence(x_train_remaining,\n",
    "                                                                                                 y_train_remaining,\n",
    "                                                                                                 x_train,\n",
    "                                                                                                 y_train)\n",
    "        engine.train_model(batch_size=64, epochs=5, x_train=x_train, y_train=y_train)\n",
    "    engine.evaluate_model(x_test, y_test)\n",
    "    engine.save_best_model()\n"
   ],
   "metadata": {
    "id": "4gpL3UO2nVfA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels retreived for training: \n",
      "10417\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 28, 28, 32)   320         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 28, 28, 32)   9248        ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 28, 28, 64)   18496       ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 64)  0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 14, 14, 64)   36928       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 14, 14, 64)   0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 14, 14, 64)   36928       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 14, 14, 64)   0           ['conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 14, 14, 64)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 64)    0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 7, 7, 128)    73856       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 7, 7, 128)    0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 7, 7, 128)    147584      ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 3, 3, 128)   0           ['conv2d_24[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 3, 3, 256)    295168      ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 3, 3, 256)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 3, 3, 256)    590080      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 1, 1, 256)   0           ['conv2d_26[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 256)          0           ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 256)          0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1024)         263168      ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 1024)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 512)          524800      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 512)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 10)           5130        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,001,706\n",
      "Trainable params: 2,001,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "  1/131 [..............................] - ETA: 2:09 - loss: 2.3019 - accuracy: 0.1094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22548\\1759737772.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22548\\4268490386.py\u001B[0m in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mbest_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[0my_train_remaining\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22548\\538632076.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(self, epochs, batch_size, x_train, y_train)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0msave_best_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1562\u001B[0m                         ):\n\u001B[0;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1564\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1565\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2495\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m   2496\u001B[0m     return graph_function._call_flat(\n\u001B[1;32m-> 2497\u001B[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0m\u001B[0;32m   2498\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2499\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1861\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1862\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[1;32m-> 1863\u001B[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[0;32m   1864\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    502\u001B[0m               \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    503\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mattrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 504\u001B[1;33m               ctx=ctx)\n\u001B[0m\u001B[0;32m    505\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    506\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[1;32mC:\\w\\interview tasks\\nt_t3_classify_least_lbl\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[1;32m---> 55\u001B[1;33m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# plt.title('Epoch-Accuracy Graph')\n",
    "# plt.xlabel = 'Epochs'\n",
    "# plt.ylabel = 'Loss'\n",
    "# plt.plot(range(1, len(hist.epoch) + 1), hist.history['accuracy'])\n",
    "# plt.plot(range(1, len(hist.epoch) + 1), hist.history['val_accuracy'])\n",
    "# plt.legend(['accuracy', 'val_accuracy'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "id": "4J_uWE4WnVfA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "131/131 [==============================] - 3s 14ms/step - loss: 1.2194 - accuracy: 0.5247 - val_loss: 0.8133 - val_accuracy: 0.7217\n",
      "Epoch 2/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.6338 - accuracy: 0.7589 - val_loss: 0.5502 - val_accuracy: 0.7893\n",
      "Epoch 3/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.5112 - accuracy: 0.8080 - val_loss: 0.4391 - val_accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.4420 - accuracy: 0.8348 - val_loss: 0.4279 - val_accuracy: 0.8325\n",
      "Epoch 5/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.3808 - accuracy: 0.8618 - val_loss: 0.3890 - val_accuracy: 0.8618\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8530\n",
      "loss = 0.40642213821411133, accuracy = 0.8529999852180481\n",
      "1550/1550 [==============================] - 4s 2ms/step\n",
      "Remaining unlabeled: 25486\n",
      "Epoch 1/5\n",
      "432/432 [==============================] - 6s 12ms/step - loss: 0.1658 - accuracy: 0.9439 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "Epoch 2/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1419 - accuracy: 0.9523 - val_loss: 0.0309 - val_accuracy: 0.9913\n",
      "Epoch 3/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1311 - accuracy: 0.9549 - val_loss: 0.0388 - val_accuracy: 0.9899\n",
      "Epoch 4/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1194 - accuracy: 0.9585 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1144 - accuracy: 0.9597 - val_loss: 0.0086 - val_accuracy: 0.9972\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8814\n",
      "loss = 0.36766791343688965, accuracy = 0.8813999891281128\n",
      "797/797 [==============================] - 2s 2ms/step\n",
      "Remaining unlabeled: 14490\n",
      "Epoch 1/5\n",
      "569/569 [==============================] - 7s 12ms/step - loss: 0.0982 - accuracy: 0.9665 - val_loss: 0.1560 - val_accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0863 - accuracy: 0.9720 - val_loss: 0.0801 - val_accuracy: 0.9806\n",
      "Epoch 3/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 0.1374 - val_accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0790 - accuracy: 0.9735 - val_loss: 0.0566 - val_accuracy: 0.9873\n",
      "Epoch 5/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.1164 - val_accuracy: 0.9687\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8856\n",
      "loss = 0.3987918496131897, accuracy = 0.8855999708175659\n",
      "453/453 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 10590\n",
      "Epoch 1/5\n",
      "618/618 [==============================] - 8s 12ms/step - loss: 0.0840 - accuracy: 0.9744 - val_loss: 0.1980 - val_accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0770 - accuracy: 0.9752 - val_loss: 0.2030 - val_accuracy: 0.9275\n",
      "Epoch 3/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.1345 - val_accuracy: 0.9554\n",
      "Epoch 4/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.1888 - val_accuracy: 0.9342\n",
      "Epoch 5/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.1428 - val_accuracy: 0.9555\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8921\n",
      "loss = 0.3925720155239105, accuracy = 0.8920999765396118\n",
      "331/331 [==============================] - 1s 2ms/step\n",
      "Remaining unlabeled: 9472\n",
      "Epoch 1/5\n",
      "632/632 [==============================] - 9s 12ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.2098 - val_accuracy: 0.9491\n",
      "Epoch 2/5\n",
      "632/632 [==============================] - 7s 11ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.1910 - val_accuracy: 0.9449\n",
      "Epoch 3/5\n",
      "632/632 [==============================] - 7s 12ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.2846 - val_accuracy: 0.9145\n",
      "Epoch 4/5\n",
      "632/632 [==============================] - 7s 11ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.1832 - val_accuracy: 0.9464\n",
      "Epoch 5/5\n",
      "632/632 [==============================] - 7s 12ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 0.1661 - val_accuracy: 0.9526\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.8925\n",
      "loss = 0.4356892704963684, accuracy = 0.8924999833106995\n",
      "296/296 [==============================] - 1s 2ms/step\n",
      "Remaining unlabeled: 7372\n",
      "Epoch 1/5\n",
      "658/658 [==============================] - 9s 13ms/step - loss: 0.0675 - accuracy: 0.9803 - val_loss: 0.2595 - val_accuracy: 0.9122\n",
      "Epoch 2/5\n",
      "658/658 [==============================] - 7s 11ms/step - loss: 0.0628 - accuracy: 0.9819 - val_loss: 0.2324 - val_accuracy: 0.9286\n",
      "Epoch 3/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0548 - accuracy: 0.9821 - val_loss: 0.2537 - val_accuracy: 0.9300\n",
      "Epoch 4/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.2409 - val_accuracy: 0.9361\n",
      "Epoch 5/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.2028 - val_accuracy: 0.9501\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6137 - accuracy: 0.8995\n",
      "loss = 0.6136929988861084, accuracy = 0.8995000123977661\n",
      "231/231 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 5579\n",
      "Epoch 1/5\n",
      "681/681 [==============================] - 8s 11ms/step - loss: 0.0788 - accuracy: 0.9778 - val_loss: 0.3425 - val_accuracy: 0.8882\n",
      "Epoch 2/5\n",
      "681/681 [==============================] - 7s 11ms/step - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.3519 - val_accuracy: 0.8936\n",
      "Epoch 3/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.3460 - val_accuracy: 0.9060\n",
      "Epoch 4/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 0.3048 - val_accuracy: 0.9179\n",
      "Epoch 5/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 0.3593 - val_accuracy: 0.8980\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.8924\n",
      "loss = 0.555624783039093, accuracy = 0.8924000263214111\n",
      "175/175 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 4775\n",
      "Epoch 1/5\n",
      "691/691 [==============================] - 9s 11ms/step - loss: 0.0744 - accuracy: 0.9792 - val_loss: 0.5317 - val_accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0801 - accuracy: 0.9757 - val_loss: 0.3212 - val_accuracy: 0.9092\n",
      "Epoch 3/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.3253 - val_accuracy: 0.8974\n",
      "Epoch 4/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.4410 - val_accuracy: 0.8595\n",
      "Epoch 5/5\n",
      "691/691 [==============================] - 8s 11ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.2920 - val_accuracy: 0.9141\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.9022\n",
      "loss = 0.4786585867404938, accuracy = 0.9021999835968018\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.9022\n",
      "loss = 0.4786585867404938, accuracy = 0.9021999835968018\n"
     ]
    }
   ],
   "source": [
    "# Accuracy stats and outputs\n",
    "main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd780AIdnVfA",
    "outputId": "9a57d189-6abb-45f1-b43e-19573ea3af2e"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

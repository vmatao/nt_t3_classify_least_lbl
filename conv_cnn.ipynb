{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1s8_M44GnVe8",
    "outputId": "ae8aa8db-ce63-446b-f2a7-b2c19137c63f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_data_with_n_labels_for_each_class(x_train_full, y_train_full, nr_of_labels, num_classes):\n",
    "    x_train_full, y_train_full = shuffle(x_train_full, y_train_full)\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    min_queries = nr_of_labels * num_classes\n",
    "    x_train.extend(x_train_full[0:min_queries])\n",
    "    y_train.extend(y_train_full[0:min_queries])\n",
    "\n",
    "    for index in range(min_queries, y_train_full.size):\n",
    "        x_train.append(x_train_full[index])\n",
    "        y_train.append(y_train_full[index])\n",
    "        _, classes_counter = np.unique(np.array(y_train), return_counts=True)\n",
    "        if np.amin(classes_counter) == nr_of_labels:\n",
    "            break\n",
    "\n",
    "    #TODO select random 500 from each class\n",
    "    return np.array(x_train), np.array(y_train), x_train_full[len(y_train):], y_train_full[len(y_train):]"
   ],
   "metadata": {
    "id": "-iqi9CFvnVe9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "x_train_full, y_train_full = load_mnist('data', kind='train')\n",
    "x_test, y_test = load_mnist('data', kind='t10k')\n",
    "num_classes = 10\n",
    "\n",
    "x_train, y_train, x_train_remaining, y_train_remaining = get_data_with_n_labels_for_each_class(x_train_full,\n",
    "                                                                                               y_train_full,\n",
    "                                                                                               nr_of_labels=1000,\n",
    "                                                                                               num_classes=num_classes)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ],
   "metadata": {
    "id": "_3W3rKLTnVe-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import keras.layers\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "def make_stem(inputs, filters=[32, 32, 64], shape=(32, 32, 3), kernel_size=(3, 3), padding='same', activation='relu'):\n",
    "    filter1, filter2, filter3 = filters\n",
    "    stem = keras.layers.Conv2D(filter1, kernel_size, input_shape=shape, activation=activation,\n",
    "                               padding=padding)(inputs)\n",
    "    stem = keras.layers.Conv2D(filter2, kernel_size, input_shape=shape, activation=activation,\n",
    "                               padding=padding)(stem)\n",
    "    stem = keras.layers.Conv2D(filter3, kernel_size, input_shape=shape, activation=activation,\n",
    "                               padding=padding)(stem)\n",
    "    stem = keras.layers.MaxPooling2D(kernel_size, strides=(2, 2), padding=padding)(stem)\n",
    "    return stem\n",
    "\n",
    "\n",
    "def make_skip_connection(input, filter=64, kernel_size=(3, 3), padding='same', activation='relu', dropout=0.2):\n",
    "    skip = keras.layers.Conv2D(filter, kernel_size, activation=activation, padding=padding)(input)\n",
    "    layer = keras.layers.Dropout(dropout)(skip)\n",
    "    layer = keras.layers.Conv2D(filter, kernel_size, padding=padding)(layer)\n",
    "    merge = keras.layers.add([layer, skip])\n",
    "    activation = keras.layers.Activation('relu')(merge)\n",
    "    return activation\n",
    "\n",
    "\n",
    "def make_main_block(input, filter=64, kernel_size=(3, 3), padding='same', activation='relu', dropout=0.2,\n",
    "                    pool_size=(2, 2)):\n",
    "    block = keras.layers.Conv2D(filter, kernel_size, activation=activation, padding=padding)(input)\n",
    "    block = keras.layers.Dropout(dropout)(block)\n",
    "    block = keras.layers.Conv2D(filter, kernel_size, activation=activation, padding=padding)(block)\n",
    "    block = keras.layers.MaxPooling2D(pool_size=pool_size)(block)\n",
    "    return block\n",
    "\n",
    "\n",
    "def make_dense_dropout(input, filter, kernel_constraint=maxnorm(3), activation='relu', dropout=0.2):\n",
    "    dense = keras.layers.Dense(filter, activation=activation, kernel_constraint=kernel_constraint)(input)\n",
    "    dropout = keras.layers.Dropout(dropout)(dense)\n",
    "    return dropout"
   ],
   "metadata": {
    "id": "UZX1-tA0nVe-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 7, 7, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 3, 3, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 3, 3, 256)         295168    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 1, 1, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,927,850\n",
      "Trainable params: 1,927,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shape = (28, 28, 1)\n",
    "pool_size = (2, 2)\n",
    "dropout = 0.2\n",
    "inputs = keras.Input(shape=shape)\n",
    "output = make_stem(inputs)\n",
    "\n",
    "output = keras.layers.MaxPooling2D(pool_size=pool_size)(output)\n",
    "\n",
    "output = make_main_block(output, 128)\n",
    "output = make_main_block(output, 256)\n",
    "\n",
    "output = keras.layers.Flatten()(output)\n",
    "output = keras.layers.Dropout(dropout)(output)\n",
    "\n",
    "output = make_dense_dropout(output, 1024)\n",
    "output = make_dense_dropout(output, 512)\n",
    "\n",
    "output = keras.layers.Dense(num_classes, activation='softmax')(output)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVEGncmfnVe_",
    "outputId": "a2ed66ca-d8ee-4d5b-ee63-3318381da9c5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, Dense, Flatten\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu', name='Convolution-1'))\n",
    "# model.add(MaxPooling2D(name='MaxPooling2D-1'))\n",
    "# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name='Convolution-2'))\n",
    "# model.add(MaxPooling2D(name='MaxPooling2D-2'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, activation='relu', name='Hidden-1'))\n",
    "# model.add(Dense(512, activation='relu', name='Hidden-2'))\n",
    "# model.add(Dense(10, activation='softmax', name='Output'))\n",
    "\n",
    "# model.summary()"
   ],
   "metadata": {
    "id": "04JlWKl8nVe_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def main(x_train, y_train, x_train_remaining, y_train_remaining):\n",
    "    accuracy = 0\n",
    "    best_model = None\n",
    "    model = train_model(epochs=5, batch_size=64, x_train=x_train, y_train=y_train)\n",
    "    while y_train_remaining.size > 0:\n",
    "        curr_accuracy = evaluate_model(model)\n",
    "        if curr_accuracy > accuracy:\n",
    "            best_model = model\n",
    "            accuracy = curr_accuracy\n",
    "            if accuracy > 0.9:\n",
    "                best_model.save(\"best.h5\")\n",
    "                break\n",
    "        x_train, y_train, x_train_remaining, y_train_remaining = classify_high_confidence(x_train_remaining,\n",
    "                                                                                          y_train_remaining, x_train,\n",
    "                                                                                          y_train)\n",
    "        retrain_model(model=model, batch_size=64, epochs=5, x_train=x_train, y_train=y_train)\n",
    "    curr_accuracy = evaluate_model(model)\n",
    "    if curr_accuracy > accuracy:\n",
    "        best_model = model\n",
    "    best_model.save(\"best.h5\")\n",
    "\n",
    "\n",
    "def classify_high_confidence(x_train_remaining, y_train_remaining, x_train, y_train):\n",
    "    input = x_train_remaining.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "    predictions = model.predict(input)\n",
    "    certainty = predictions.copy()\n",
    "    certainty = np.max(certainty, axis=1)\n",
    "    certainty = np.expand_dims(certainty, axis=1)\n",
    "\n",
    "    label = predictions.copy()\n",
    "    label = np.argmax(label, axis=1)\n",
    "\n",
    "    categ_label = to_categorical(label,num_classes = 10)\n",
    "\n",
    "    certainty_threshold = 0.95\n",
    "    indices_over_threshold = np.where(np.any(certainty > certainty_threshold, axis=1))\n",
    "\n",
    "    x_train = np.append(x_train, input[indices_over_threshold], axis=0)\n",
    "    y_train = np.append(y_train, categ_label[indices_over_threshold], axis=0)\n",
    "    x_train_remaining = np.delete(x_train_remaining, [indices_over_threshold], axis=0)\n",
    "    y_train_remaining = np.delete(y_train_remaining, [indices_over_threshold], axis=0)\n",
    "\n",
    "    print(\"Remaining unlabeled: \" + str(y_train_remaining.size))\n",
    "    return x_train, y_train, x_train_remaining, y_train_remaining\n",
    "\n",
    "\n",
    "def evaluate_model(model):\n",
    "    loss, accuracy = model.evaluate(x_test, y_test)\n",
    "    print('loss = {}, accuracy = {}'.format(loss, accuracy))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_model(epochs, batch_size, x_train, y_train):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    return model\n",
    "\n",
    "\n",
    "def retrain_model(epochs, batch_size, model, x_train, y_train):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    return model\n"
   ],
   "metadata": {
    "id": "4gpL3UO2nVfA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# plt.title('Epoch-Accuracy Graph')\n",
    "# plt.xlabel = 'Epochs'\n",
    "# plt.ylabel = 'Loss'\n",
    "# plt.plot(range(1, len(hist.epoch) + 1), hist.history['accuracy'])\n",
    "# plt.plot(range(1, len(hist.epoch) + 1), hist.history['val_accuracy'])\n",
    "# plt.legend(['accuracy', 'val_accuracy'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "id": "4J_uWE4WnVfA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "131/131 [==============================] - 3s 14ms/step - loss: 1.2194 - accuracy: 0.5247 - val_loss: 0.8133 - val_accuracy: 0.7217\n",
      "Epoch 2/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.6338 - accuracy: 0.7589 - val_loss: 0.5502 - val_accuracy: 0.7893\n",
      "Epoch 3/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.5112 - accuracy: 0.8080 - val_loss: 0.4391 - val_accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.4420 - accuracy: 0.8348 - val_loss: 0.4279 - val_accuracy: 0.8325\n",
      "Epoch 5/5\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 0.3808 - accuracy: 0.8618 - val_loss: 0.3890 - val_accuracy: 0.8618\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4064 - accuracy: 0.8530\n",
      "loss = 0.40642213821411133, accuracy = 0.8529999852180481\n",
      "1550/1550 [==============================] - 4s 2ms/step\n",
      "Remaining unlabeled: 25486\n",
      "Epoch 1/5\n",
      "432/432 [==============================] - 6s 12ms/step - loss: 0.1658 - accuracy: 0.9439 - val_loss: 0.0200 - val_accuracy: 0.9952\n",
      "Epoch 2/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1419 - accuracy: 0.9523 - val_loss: 0.0309 - val_accuracy: 0.9913\n",
      "Epoch 3/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1311 - accuracy: 0.9549 - val_loss: 0.0388 - val_accuracy: 0.9899\n",
      "Epoch 4/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1194 - accuracy: 0.9585 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 5/5\n",
      "432/432 [==============================] - 5s 11ms/step - loss: 0.1144 - accuracy: 0.9597 - val_loss: 0.0086 - val_accuracy: 0.9972\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3677 - accuracy: 0.8814\n",
      "loss = 0.36766791343688965, accuracy = 0.8813999891281128\n",
      "797/797 [==============================] - 2s 2ms/step\n",
      "Remaining unlabeled: 14490\n",
      "Epoch 1/5\n",
      "569/569 [==============================] - 7s 12ms/step - loss: 0.0982 - accuracy: 0.9665 - val_loss: 0.1560 - val_accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0863 - accuracy: 0.9720 - val_loss: 0.0801 - val_accuracy: 0.9806\n",
      "Epoch 3/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0812 - accuracy: 0.9717 - val_loss: 0.1374 - val_accuracy: 0.9750\n",
      "Epoch 4/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0790 - accuracy: 0.9735 - val_loss: 0.0566 - val_accuracy: 0.9873\n",
      "Epoch 5/5\n",
      "569/569 [==============================] - 6s 11ms/step - loss: 0.0778 - accuracy: 0.9738 - val_loss: 0.1164 - val_accuracy: 0.9687\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8856\n",
      "loss = 0.3987918496131897, accuracy = 0.8855999708175659\n",
      "453/453 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 10590\n",
      "Epoch 1/5\n",
      "618/618 [==============================] - 8s 12ms/step - loss: 0.0840 - accuracy: 0.9744 - val_loss: 0.1980 - val_accuracy: 0.9237\n",
      "Epoch 2/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0770 - accuracy: 0.9752 - val_loss: 0.2030 - val_accuracy: 0.9275\n",
      "Epoch 3/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.1345 - val_accuracy: 0.9554\n",
      "Epoch 4/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.1888 - val_accuracy: 0.9342\n",
      "Epoch 5/5\n",
      "618/618 [==============================] - 7s 11ms/step - loss: 0.0614 - accuracy: 0.9798 - val_loss: 0.1428 - val_accuracy: 0.9555\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3926 - accuracy: 0.8921\n",
      "loss = 0.3925720155239105, accuracy = 0.8920999765396118\n",
      "331/331 [==============================] - 1s 2ms/step\n",
      "Remaining unlabeled: 9472\n",
      "Epoch 1/5\n",
      "632/632 [==============================] - 9s 12ms/step - loss: 0.0695 - accuracy: 0.9790 - val_loss: 0.2098 - val_accuracy: 0.9491\n",
      "Epoch 2/5\n",
      "632/632 [==============================] - 7s 11ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.1910 - val_accuracy: 0.9449\n",
      "Epoch 3/5\n",
      "632/632 [==============================] - 7s 12ms/step - loss: 0.0558 - accuracy: 0.9823 - val_loss: 0.2846 - val_accuracy: 0.9145\n",
      "Epoch 4/5\n",
      "632/632 [==============================] - 7s 11ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 0.1832 - val_accuracy: 0.9464\n",
      "Epoch 5/5\n",
      "632/632 [==============================] - 7s 12ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 0.1661 - val_accuracy: 0.9526\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.8925\n",
      "loss = 0.4356892704963684, accuracy = 0.8924999833106995\n",
      "296/296 [==============================] - 1s 2ms/step\n",
      "Remaining unlabeled: 7372\n",
      "Epoch 1/5\n",
      "658/658 [==============================] - 9s 13ms/step - loss: 0.0675 - accuracy: 0.9803 - val_loss: 0.2595 - val_accuracy: 0.9122\n",
      "Epoch 2/5\n",
      "658/658 [==============================] - 7s 11ms/step - loss: 0.0628 - accuracy: 0.9819 - val_loss: 0.2324 - val_accuracy: 0.9286\n",
      "Epoch 3/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0548 - accuracy: 0.9821 - val_loss: 0.2537 - val_accuracy: 0.9300\n",
      "Epoch 4/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.2409 - val_accuracy: 0.9361\n",
      "Epoch 5/5\n",
      "658/658 [==============================] - 8s 12ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.2028 - val_accuracy: 0.9501\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6137 - accuracy: 0.8995\n",
      "loss = 0.6136929988861084, accuracy = 0.8995000123977661\n",
      "231/231 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 5579\n",
      "Epoch 1/5\n",
      "681/681 [==============================] - 8s 11ms/step - loss: 0.0788 - accuracy: 0.9778 - val_loss: 0.3425 - val_accuracy: 0.8882\n",
      "Epoch 2/5\n",
      "681/681 [==============================] - 7s 11ms/step - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.3519 - val_accuracy: 0.8936\n",
      "Epoch 3/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.3460 - val_accuracy: 0.9060\n",
      "Epoch 4/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0533 - accuracy: 0.9821 - val_loss: 0.3048 - val_accuracy: 0.9179\n",
      "Epoch 5/5\n",
      "681/681 [==============================] - 8s 12ms/step - loss: 0.0487 - accuracy: 0.9845 - val_loss: 0.3593 - val_accuracy: 0.8980\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.8924\n",
      "loss = 0.555624783039093, accuracy = 0.8924000263214111\n",
      "175/175 [==============================] - 1s 3ms/step\n",
      "Remaining unlabeled: 4775\n",
      "Epoch 1/5\n",
      "691/691 [==============================] - 9s 11ms/step - loss: 0.0744 - accuracy: 0.9792 - val_loss: 0.5317 - val_accuracy: 0.8297\n",
      "Epoch 2/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0801 - accuracy: 0.9757 - val_loss: 0.3212 - val_accuracy: 0.9092\n",
      "Epoch 3/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.3253 - val_accuracy: 0.8974\n",
      "Epoch 4/5\n",
      "691/691 [==============================] - 7s 11ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.4410 - val_accuracy: 0.8595\n",
      "Epoch 5/5\n",
      "691/691 [==============================] - 8s 11ms/step - loss: 0.0519 - accuracy: 0.9834 - val_loss: 0.2920 - val_accuracy: 0.9141\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.9022\n",
      "loss = 0.4786585867404938, accuracy = 0.9021999835968018\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.9022\n",
      "loss = 0.4786585867404938, accuracy = 0.9021999835968018\n"
     ]
    }
   ],
   "source": [
    "main(x_train, y_train, x_train_remaining, y_train_remaining)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bd780AIdnVfA",
    "outputId": "9a57d189-6abb-45f1-b43e-19573ea3af2e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "WDpxyWvcnVfB"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
